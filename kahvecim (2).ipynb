{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AKBANK GENAI BOOTCAMP PROJESÄ°: KAHVE TARÄ°FLERÄ° RAG CHATBOT'U\n",
        "\n",
        "**Projenin AmacÄ±:** RAG (Retrieval Augmented Generation) mimarisini kullanarak kahve tarifleri hakkÄ±nda doÄŸru bilgi saÄŸlayan bir chatbot geliÅŸtirmek ve Gradio arayÃ¼zÃ¼ ile sunmaktÄ±r.\n",
        "\n",
        "**DeÄŸerlendirme Kriterleri:** Bu Notebook, projenin tÃ¼m deÄŸerlendirme kriterlerini karÅŸÄ±layacak ÅŸekilde (Veri Seti HazÄ±rlama, Ã‡alÄ±ÅŸma KÄ±lavuzu, Ã‡Ã¶zÃ¼m Mimarisi, Web ArayÃ¼zÃ¼/Product KÄ±lavuzu) belgelenmiÅŸtir.\n",
        "---"
      ],
      "metadata": {
        "id": "LafLY9D54no4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcBcVuFEx2wT"
      },
      "outputs": [],
      "source": [
        "# Gerekli LangChain, Gemini entegrasyonu, ChromaDB, ve BGE Embeddings kÃ¼tÃ¼phanelerini kuralÄ±m\n",
        "!pip install -q langchain langchain-google-genai chromadb pypdf langchain-community sentence-transformers gradio\n",
        "print(\"Gerekli kÃ¼tÃ¼phaneler kuruldu.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ› ï¸ 3. PROJE ADIMI: KODUNUZUN Ã‡ALIÅMA KILAVUZU\n",
        "\n",
        "Projenin baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±labilmesi iÃ§in gereken adÄ±mlar ve gereksinimler:\n",
        "\n",
        "1.  **Gereksinimler:** Python 3.10+ ve Colab Notebook ortamÄ± kullanÄ±lmalÄ±dÄ±r.\n",
        "2.  **KÃ¼tÃ¼phane Kurulumu:** Notebook'taki ilk hÃ¼crede bulunan `!pip install ...` komutlarÄ± ile tÃ¼m baÄŸÄ±mlÄ±lÄ±klar kurulur.\n",
        "3.  **API AnahtarÄ±:** Google Gemini API anahtarÄ± alÄ±nmalÄ± ve **'GEMINI_API_KEY'** adÄ±yla Colab Secrets'a (SÄ±rlar) tanÄ±mlanmalÄ±dÄ±r.\n",
        "4.  **Ã‡alÄ±ÅŸtÄ±rma:** Notebook'taki hÃ¼creler, sÄ±rayla ve hatasÄ±z bir ÅŸekilde Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±dÄ±r. Ä°lgili python (veya notebook) dosyanÄ±zÄ±n Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± gibi adÄ±mlar burada yer alacaktÄ±r."
      ],
      "metadata": {
        "id": "Qz98IIqq497-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# LÃ¼tfen Colab'Ä±n sol panelindeki Anahtar (ğŸ”’) simgesine tÄ±klayarak\n",
        "# 'GEMINI_API_KEY' adÄ±yla API anahtarÄ±nÄ±zÄ± eklediÄŸinizden emin olun.\n",
        "\n",
        "try:\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
        "    print(\"API AnahtarÄ± baÅŸarÄ±yla ayarlandÄ±.\")\n",
        "except Exception as e:\n",
        "    print(f\"HATA: API anahtarÄ± ayarlanÄ±rken sorun oluÅŸtu. Detay: {e}\")\n",
        "    print(\"LÃ¼tfen 'GEMINI_API_KEY' adÄ±yla API anahtarÄ±nÄ±zÄ± Colab Secrets'a ekleyin.\")\n",
        "\n",
        "# GeliÅŸtirme iÃ§in kullanÄ±lacak modeller\n",
        "# Embedding iÃ§in stabil bir HF modeli, LLM iÃ§in Gemini kullanacaÄŸÄ±z.\n",
        "EMBEDDING_MODEL = \"BAAI/bge-small-en-v1.5\"\n",
        "LLM_MODEL = \"gemini-2.5-flash\"\n",
        "print(f\"Embedding Model: {EMBEDDING_MODEL}\")\n",
        "print(f\"LLM Model: {LLM_MODEL}\")"
      ],
      "metadata": {
        "id": "p8Qj4wobyTGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "FILE_PATH = \"kahve_tarifleri.txt\"\n",
        "\n",
        "# Metin dosyasÄ±nÄ± LangChain'in TextLoader'Ä± ile okuyun\n",
        "loader = TextLoader(FILE_PATH)\n",
        "documents = loader.load()\n",
        "\n",
        "print(f\"Veri dosyasÄ± yÃ¼klendi. Toplam {len(documents)} adet dokÃ¼man bulundu.\")\n",
        "print(f\"Ä°lk 100 karakter: {documents[0].page_content[:100]}...\")"
      ],
      "metadata": {
        "id": "oUxmIxF3ya1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# â˜• 2. PROJE ADIMI: VERÄ° SETÄ° HAZIRLAMA\n",
        "\n",
        "Bu projede kullanÄ±lan veri seti, **24 farklÄ± popÃ¼ler kahve tarifini (TÃ¼rk Kahvesi, Latte, Mocha, Cold Brew vb.)** ve bunlarÄ±n yapÄ±lÄ±ÅŸ adÄ±mlarÄ±nÄ±, malzemelerini iÃ§eren **kahve_tarifleri.txt** adlÄ± metin dosyasÄ±dÄ±r.\n",
        "\n",
        "Veri setinizle ilgili genel bilgilerden, iÃ§eriÄŸinden ve proje konunuzdan bahsetmeniz yeterlidir. Veri, RAG sisteminin bilgi tabanÄ±nÄ± oluÅŸturmaktadÄ±r."
      ],
      "metadata": {
        "id": "bHaFyWFV44Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ—ï¸ 4. PROJE ADIMI: Ã‡Ã–ZÃœM MÄ°MARÄ°NÄ°Z\n",
        "\n",
        "Bu proje, LangChain Ã§erÃ§evesini kullanan standart bir RAG (Retrieval Augmented Generation) mimarisi ile tasarlanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "**Projenin Ã‡Ã¶zdÃ¼ÄŸÃ¼ Problem:** KullanÄ±cÄ±larÄ±n statik bir dokÃ¼mandan (kahve tarifleri) aradÄ±klarÄ± bilgiyi, karmaÅŸÄ±k bir arama yapmadan, doÄŸal dil kullanarak anÄ±nda doÄŸru bir ÅŸekilde almasÄ±nÄ± saÄŸlamaktÄ±r.\n",
        "\n",
        "**RAG Mimarisi BileÅŸenleri:**\n",
        "\n",
        "| RAG AÅŸamasÄ± | BileÅŸen | KullanÄ±lan Teknoloji | AÃ§Ä±klama |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **1. Veri HazÄ±rlÄ±ÄŸÄ±** | Loader & Splitter | `TextLoader` & `RecursiveCharacterTextSplitter` | Veri, hassasiyet iÃ§in $400$ karakterlik parÃ§alara ayrÄ±lÄ±r. |\n",
        "| **2. GÃ¶mme (Embedding)** | Embedding Model | HuggingFace BGE Embeddings | ParÃ§alar, arama iÃ§in sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. |\n",
        "| **3. Depolama & EriÅŸim** | Vector Store & Retriever | ChromaDB & `db.as_retriever()` | VektÃ¶rler saklanÄ±r. Sorgu geldiÄŸinde, en alakalÄ± $3$ parÃ§a (`k=3`) geri getirilir. |\n",
        "| **4. Ãœretme (Generation)** | LLM & Prompt | Gemini 2.5 Flash | Geri getirilen baÄŸlam, $\\text{Gemini}$'a gÃ¶nderilerek son yanÄ±t Ã¼retilir. |"
      ],
      "metadata": {
        "id": "zjoM1C7C5Suz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# RAG hassasiyetini artÄ±rmak iÃ§in kÃ¼Ã§Ã¼k parÃ§alar ve Ã§akÄ±ÅŸma kullanÄ±yoruz\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=400,       # Daha kÃ¼Ã§Ã¼k parÃ§a boyutu\n",
        "    chunk_overlap=100,    # ParÃ§alar arasÄ± Ã§akÄ±ÅŸma\n",
        ")\n",
        "\n",
        "# Belgeleri parÃ§alara ayÄ±rÄ±n\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Toplam bÃ¶lÃ¼nmÃ¼ÅŸ parÃ§a (chunk) sayÄ±sÄ±: {len(texts)}\")"
      ],
      "metadata": {
        "id": "Iix4giVVyf9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# BGE Embeddings modelini kullanÄ±n (stabil ve Google API'a baÄŸÄ±mlÄ± deÄŸil)\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "\n",
        "embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=EMBEDDING_MODEL,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "print(\"HuggingFace Bge Embeddings modeli yÃ¼klendi.\")\n",
        "\n",
        "# ChromaDB veritabanÄ±nÄ± oluÅŸturun ve veriyi ekleyin.\n",
        "db = Chroma.from_documents(texts, embeddings, persist_directory=\"./kahve_chroma_db\")\n",
        "\n",
        "print(\"ChromaDB VektÃ¶r VeritabanÄ± oluÅŸturuldu ve veriler eklendi.\")\n",
        "\n",
        "# VektÃ¶r veritabanÄ±nÄ± bir Geri Getirici'ye (Retriever) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n.\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "print(\"Retriever (Geri Getirici) kullanÄ±ma hazÄ±r.\")"
      ],
      "metadata": {
        "id": "UDQopuOgyjhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Gemini LLM Modelini ayarlayÄ±n (Generation adÄ±mÄ± iÃ§in)\n",
        "llm = ChatGoogleGenerativeAI(model=LLM_MODEL, temperature=0.2, api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# RAG iÃ§in kullanÄ±lacak Åablonu (Prompt) tanÄ±mlayÄ±n\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"Sen bir Kahve Tarifleri UzmanÄ± Chatbot'sun. YalnÄ±zca saÄŸlanan 'BaÄŸlam'daki kahve tariflerini kullanarak kullanÄ±cÄ± sorularÄ±nÄ± yanÄ±tla. \"\n",
        "     \"EÄŸer tarif baÄŸlamda yoksa, kibarca 'Bu tarifi maalesef bilgi kaynaklarÄ±mda bulamadÄ±m.' de.\"\n",
        "     \"\\n\\nBaÄŸlam: {context}\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "])\n",
        "\n",
        "# DokÃ¼manlarÄ± birleÅŸtiren zinciri oluÅŸturun\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Geri getirme ve Ãœretme zincirlerini birleÅŸtirin\n",
        "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
        "\n",
        "print(\"RAG Zinciri oluÅŸturuldu. Åimdi test edelim.\")\n",
        "\n",
        "# TEST 1: Bilgi KaynaÄŸÄ±nda Olan Soru (Latte tarifi)\n",
        "test_soru_1 = \"Latte nasÄ±l yapÄ±lÄ±r? AdÄ±mlarÄ±nÄ± sÃ¶yle.\"\n",
        "response_1 = rag_chain.invoke({\"input\": test_soru_1})\n",
        "print(f\"\\nSORGU: {test_soru_1}\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"CEVAP:\\n{response_1['answer']}\")"
      ],
      "metadata": {
        "id": "2kwKw80ry1GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gradio.themes.utils import colors\n",
        "import os\n",
        "\n",
        "# Chatbot'un ana iÅŸlevini Gradio iÃ§in bir fonksiyona saralÄ±m\n",
        "def chatbot_response(message, history):\n",
        "    # 'rag_chain' objesi hafÄ±zada olmalÄ±dÄ±r.\n",
        "    try:\n",
        "        response = rag_chain.invoke({\"input\": message})\n",
        "        answer = response[\"answer\"]\n",
        "\n",
        "        # CevabÄ±n sonuna not ekleme\n",
        "        return answer + \"\\n\\n*(Bilgiler, kahve tarifleri bilgi kaynaÄŸÄ±mÄ±zdan derlenmiÅŸtir.)*\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {e}\"\n",
        "\n",
        "# Gradio arayÃ¼zÃ¼nÃ¼ oluÅŸturun (Basit ve TemalÄ± Versiyon)\n",
        "demo = gr.ChatInterface(\n",
        "    fn=chatbot_response,\n",
        "    title=\"â˜• Kahve Tarifleri UzmanÄ± Chatbot â˜•\",\n",
        "    textbox=gr.Textbox(placeholder=\"Ã–rn: Frappe nasÄ±l yapÄ±lÄ±r?\"),\n",
        "    chatbot=gr.Chatbot(height=400),\n",
        "    examples=[\"Latte nasÄ±l yapÄ±lÄ±r?\", \"Affogato iÃ§in malzemeler nelerdir?\", \"Dibek kahvesi ile TÃ¼rk kahvesi arasÄ±ndaki fark nedir?\"],\n",
        "\n",
        "    # Kahve temasÄ±na uygun renkler\n",
        "    theme=gr.themes.Soft(\n",
        "        primary_hue=colors.orange,\n",
        "        secondary_hue=colors.blue,\n",
        "        neutral_hue=colors.gray\n",
        "    ),\n",
        "    css=\"h1 {color: #6F4E37; font-family: 'Georgia', serif;}\"\n",
        ")\n",
        "\n",
        "# Colab'da Ã§alÄ±ÅŸtÄ±rmak iÃ§in \"share=True\"\n",
        "print(\"Gradio ArayÃ¼zÃ¼ baÅŸlatÄ±lÄ±yor. LÃ¼tfen Ã§Ä±kan Public URL'yi kullanÄ±n.\")\n",
        "demo.queue().launch(share=True)"
      ],
      "metadata": {
        "id": "BrPafBC6y8zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ–¥ï¸ 5. PROJE ADIMI: WEB ARAYÃœZÃœ & PRODUCT KILAVUZU\n",
        "\n",
        "Projenin canlÄ± demosu, Gradio kullanÄ±larak sunulmuÅŸtur. Bu arayÃ¼z, projenin kabiliyetlerini doÄŸrudan test etmenizi saÄŸlar.\n",
        "\n",
        "**Deploy Linkiniz:**\n",
        "(LÃ¼tfen buraya Gradio'dan aldÄ±ÄŸÄ±nÄ±z **geÃ§ici veya kalÄ±cÄ±** Public URL'yi yapÄ±ÅŸtÄ±rÄ±n.)\n",
        "\n",
        "**Ã‡alÄ±ÅŸma AkÄ±ÅŸÄ± ve Test:**\n",
        "1.  YukarÄ±daki linke tÄ±klayarak chatbot arayÃ¼zÃ¼ne eriÅŸin.\n",
        "2.  ArayÃ¼z, temalÄ± yapÄ±sÄ± sayesinde kullanÄ±cÄ± dostu bir deneyim sunar.\n",
        "3.  Projenin kabiliyetlerini test etmek iÃ§in aÅŸaÄŸÄ±daki sorularÄ± kullanabilirsiniz:\n",
        "    * **Latte Tarifi:** \"Latte nasÄ±l yapÄ±lÄ±r? AdÄ±m adÄ±m anlat.\"\n",
        "    * **Malzeme Sorgulama:** \"Affogato iÃ§in gereken malzemeler nelerdir?\"\n",
        "    * **KarÅŸÄ±laÅŸtÄ±rma:** \"Dibek kahvesi ile normal TÃ¼rk kahvesi arasÄ±ndaki fark nedir?\"\n",
        "    * **DÄ±ÅŸ Bilgi SÄ±nama:** \"Su Ä±sÄ±tÄ±cÄ±sÄ± ne zaman icat edildi?\" (Bu soruya \"bilgi kaynaklarÄ±mda bulamadÄ±m\" yanÄ±tÄ±nÄ± vermesi beklenir.)"
      ],
      "metadata": {
        "id": "u6zPuXQu5YRg"
      }
    }
  ]
}